\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Motivation}{4}{chapter.2}%
\contentsline {chapter}{\numberline {3}Presets}{5}{chapter.3}%
\contentsline {section}{\numberline {3.1}PyMARL - A multi-agent reinforcement learning framework}{5}{section.3.1}%
\contentsline {section}{\numberline {3.2}Related work}{5}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Q-Learning in single agent environments}{5}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}DQN - Deep Q-Networks}{5}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}IQL - Independent Q-Learning}{6}{subsection.3.2.3}%
\contentsline {subsection}{\numberline {3.2.4}JQL - Joint Q-Learning}{6}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}VDN - Value Decomposition Networks}{7}{subsection.3.2.5}%
\contentsline {subsection}{\numberline {3.2.6}QMIX - Monotonic Value Function Factorization}{7}{subsection.3.2.6}%
\contentsline {subsection}{\numberline {3.2.7}SMIX - Enhanced Centralized Value Functions}{8}{subsection.3.2.7}%
\contentsline {subsection}{\numberline {3.2.8}QTRAN - }{8}{subsection.3.2.8}%
\contentsline {subsection}{\numberline {3.2.9}CKL - Common Knowledge Learning}{8}{subsection.3.2.9}%
\contentsline {subsection}{\numberline {3.2.10}COMA - Counterfactual Multi-Agent Policy Gradients}{8}{subsection.3.2.10}%
\contentsline {section}{\numberline {3.3}StarCraftII Multi Agent Challenge Environment}{9}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Reward function}{9}{subsection.3.3.1}%
\contentsline {section}{\numberline {3.4}Global and local reward functions}{10}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Rewards in Multi-Agent Reinforcement Learning}{10}{subsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.1.1}Credit Assignment Problem}{11}{subsubsection.3.4.1.1}%
\contentsline {subsection}{\numberline {3.4.2}Challenges in reward shaping}{11}{subsection.3.4.2}%
\contentsline {chapter}{\numberline {4}Dynamic reward composition}{12}{chapter.4}%
\contentsline {section}{\numberline {4.1}Idea}{12}{section.4.1}%
\contentsline {section}{\numberline {4.2}Implementing a local reward function}{12}{section.4.2}%
\contentsline {section}{\numberline {4.3}Combining local and global rewards}{13}{section.4.3}%
\contentsline {chapter}{\numberline {5}Evaluation}{15}{chapter.5}%
\contentsline {section}{\numberline {5.1}Experiments}{15}{section.5.1}%
\contentsline {chapter}{\numberline {6}Conclusion}{17}{chapter.6}%
\contentsline {chapter}{\numberline {7}Future work}{18}{chapter.7}%
\contentsline {chapter}{\numberline {A}Appendix}{19}{appendix.A}%
\contentsline {section}{\numberline {A.1}SMAC - global reward function}{20}{section.A.1}%
\contentsline {section}{\numberline {A.2}SMAC with combined rewards - local reward function}{21}{section.A.2}%
\contentsline {section}{\numberline {A.3}Generalized reward combination function}{22}{section.A.3}%
\contentsline {chapter}{Bibliography}{23}{appendix*.4}%
